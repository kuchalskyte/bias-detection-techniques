---
title: "Final AUC Analysis"
author: "Luka Kuchalskyte (s3983471)"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Scenario 1

**Scenario 1**: A model is trained on the full dataset, and predictions are made for both “Blue” and “Red” individuals separately. AUC is calculated for each group to assess predictive accuracy.

This scenario involves evaluating the predictive performance of a model for two demographic groups ("Blue" and "Red") by calculating the Area Under the Curve (AUC) for each group. The analysis aims to assess whether there is a significant difference in the model's predictive accuracy between the two groups. This is particularly important for detecting bias in the model. By bootstrapping the analysis, we can quantify the variability in AUC values and formally test for differences between groups.

1. Train the Model on the Full Dataset.
  - A machine learning model (logistic regression) is trained on the entire dataset, which includes both "Blue" and "Red" individuals.
  - The model uses income and education to predict the target variable (undesired outcome: 0 = desired, 1 = undesired).

2. Stratified Predictions.
  - Predictions are made for all individuals in the dataset.
  - The dataset is split into two subgroups based on the sensitive characteristic "Colour":
    * Group 1: Individuals with Colour = BLUE
    * Group 2: Individuals with Colour = RED
    
3. AUC Calculation for Each Group.
  - The AUC, a measure of predictive performance, is calculated separately for each group:
    * AUC for "Blue" individuals (AUC BLUE)
    * AUC for "Red" individuals (AUC RED)
  - The AUC is a robust performance metric for binary classification models, as it evaluates the model's ability to distinguish between positive and negative outcomes, regardless of threshold.
  
4. Bootstrapping to Generate AUC Distributions.
  - To assess the variability in AUC across the two groups, the process is repeated for n bootstrap samples:

5. Comparing the AUC Distributions with an ANOVA.

```{r}
stratified_bootstrap <- function(data, variable1 = "Colour", 
                                 variable2 = "Disability", n_resamples = 100, 
                                 seed) {
  
  # In: data: A data frame containing the variables of interest;
  #         - Income: Simulated income values;
  #         - Education: Assigned education levels (0 = LOW, 1 = HIGH);
  #         - Colour: Assigned colour (0 = BLUE, 1 = RED);
  #         - Disability: Variable representing whether the individual 
  #                   has a disability (0 = no disability, 1 = has disability);
  #         - Outcome: Binary variable representing whether the individual 
  #                   experienced the undesired outcome (0 = desired, 1 = undesired);
  #     variable1: A string indicating the first categorical variable (default = "Colour");
  #     variable2: A string indicating the second categorical variable (default = "Disability");
  #     n_resamples: The number of bootstrap resamples to generate (default = 100);
  #     seed: The random seed used for the sampling.
  # Out:  A list of bootstrap samples maintaining the proportional representation of Colour and Disability.
  
  # Load relevant package
  library(dplyr)
  
  # Set a seed for reproducability
  set.seed(seed) 

  # Calculate the original proportions of each demographic group
  original_proportions <- data %>%
    group_by(!!sym(variable1), !!sym(variable2)) %>%
    summarise(n = n(), .groups = "drop") %>%
    mutate(proportion = n / sum(n))

  # Initialize an empty list to store the bootstrap samples
  bootstrap_samples <- list()

  # Perform stratified bootstrapping
  for (i in 1:n_resamples) {
    
    # Initialize an empty data frame for each bootstrap sample
    bootstrap_sample <- data.frame()

    # Resample within each demographic group to maintain group proportions
    for (j in 1:nrow(original_proportions)) {
      
      # Filter data for the current group
      group_data <- data %>%
        filter(!!sym(variable1) == original_proportions[[variable1]][j],
               !!sym(variable2) == original_proportions[[variable2]][j])

      # Calculate the number of samples to draw from this group
      n_samples <- round(original_proportions$proportion[j] * nrow(data))

      # Draw a bootstrap sample from the group with replacement
      group_resample <- group_data[sample(1:nrow(group_data), size = n_samples, 
                                          replace = TRUE), ]

      # Bind the resampled group data to the bootstrap sample
      bootstrap_sample <- rbind(bootstrap_sample, group_resample)
    }
    
    # Store the bootstrap sample in the list
    bootstrap_samples[[i]] <- bootstrap_sample
  }
  
  # Return the list of bootstrap samples
  return(bootstrap_samples)
}
```

```{r}
# Function for Scenario 1: Train on Full dataset and Test on Blue/Red
auc_anova_1 <- function(data, variable1 = "Colour", 
                        variable2 = "Disability", n_resamples = 100, 
                        seed, dist, formula = "Outcome ~ Income + Education", 
                        family = binomial, response = "Outcome", type = "response") {
  
  #  In: data: The dataset used for bootstrapping and modeling;
  #      variable1: A string indicating the first categorical variable (default = "Colour");
  #      variable2: A string indicating the second categorical variable (default = "Disability");
  #      n_resamples: Number of resamples for stratified bootstrapping (default = 100);
  #      seed: Seed for reproducibility;
  #      dist: Proportion for splitting data into train and test sets;
  #      formula: A formula specifying the model (default = "Outcome ~ Income + Education");
  #      family: The family for the GLM model (default = binomial);
  #      response: The name of the response variable as a string (default = "Outcome");
  #      type: The type of prediction (default = "response").
  # Out: A list containing the following elements:
  #      - mean_auc: A summary data frame with mean AUC values for Blue and Red groups.
  #      - AUC_result: A data frame in long format containing the AUC values 
  #                    for each bootstrap iteration and each group (Blue and Red).
  #                    Columns include:
  #                      * Bootstrap: The bootstrap iteration number.
  #                      * Group: The group (Blue or Red) for which AUC is calculated.
  #                      * AUC: The AUC value for that group in the given iteration.
  #      - anova_result: The summary of an ANOVA test performed on the AUC values
  #                      to assess whether there are significant differences 
  #                      between the Blue and Red groups.
  #      - visualisation: A ggplot2 density plot showing the distribution of AUC 
  #                       values for the Blue and Red groups across all bootstrap samples.
  
  # Load necessary packages
  library(dplyr)
  library(pROC)
  library(ggplot2)
  
  # Generate n_bootstrap samples using the bootstrap function
  bootstrap_samples <- stratified_bootstrap(data = data, 
                                            variable1 = variable1, 
                                            variable2 = variable2, 
                                            n_resamples = n_resamples,
                                            seed = seed)

  # Initialize a data frame to store AUC results in long format
  auc_results <- data.frame(Bootstrap = integer(n_resamples * 2), 
                            Group = character(n_resamples * 2), 
                            AUC = numeric(n_resamples * 2))
  
  # Loop through each bootstrap sample
  for (i in 1:n_resamples) {
    
    # Get the current bootstrap sample
    sample <- bootstrap_samples[[i]]
    
    # Split the bootstrap sample into train and test sets
    set.seed(seed)
    test.index <- sample(nrow(sample), nrow(sample) * dist) 
    train <- sample[-test.index, ]
    test <- sample[test.index, ]
    
    # Train the model on the training data
    model <- glm(formula = formula, data = train, family = family)
    
    # Predict outcomes separately for Colour = 0 (Blue) and Colour = 1 (Red)
    test_blue <- test %>% filter(!!sym(variable1) == 0)
    test_red <- test %>% filter(!!sym(variable1) == 1)

    # Predict probabilities for Colour groups
    predictions_blue <- predict(model, newdata = test_blue, type = "response")
    predictions_red <- predict(model, newdata = test_red, type = "response")
    
    # Calculate AUC for Colour groups separately
    auc_blue <- if (nrow(test_blue) > 0) {
      roc(test_blue[[response]], predictions_blue)$auc
    } else NA

    auc_red <- if (nrow(test_red) > 0) {
      roc(test_red[[response]], predictions_red)$auc
    } else NA
    
    # Store results in long-format data frame
    auc_results[(i-1)*2 + 1, ] <- c(i, "Blue", auc_blue)
    auc_results[(i-1)*2 + 2, ] <- c(i, "Red", auc_red)
  }

  # Calculate Mean AUC values for each group
  mean_auc <- auc_results %>%
    group_by(Group) %>%
    summarize(mean_AUC = mean(AUC, na.rm = TRUE)) %>%
    ungroup()
  
  # Perform ANOVA on AUC results to test if there are significant differences between groups
  anova_model <- aov(AUC ~ Group, data = auc_results)
  anova_summary <- summary(anova_model)
  
  # Plot the AUC distributions for each Colour group
  plot <- ggplot(auc_results, aes(x = AUC, fill = Group)) +
    geom_density(alpha = 0.5) +
    scale_fill_manual(values = c("Blue" = "blue", "Red" = "red")) +
    labs(title = "Density Plot of AUC Distributions for Blue and Red Groups",
         x = "AUC",
         y = "Density") +
    theme_minimal()

  # Return the auc results, anova results and visualisation
  return(list(
    mean_auc = mean_auc,           # Data frame summarizing the mean AUC values for Blue and Red groups.
    AUC_result = auc_results,      # Long-format data frame with AUC values for each bootstrap iteration and group.
    anova_result = anova_summary,  # Summary of the ANOVA test assessing differences between groups.
    visualisation = plot))         # Density plot visualizing the AUC distribution for Blue and Red groups.
}
```

```{r}
# Method B (AUC Analysis) Scenario 1 Heatmap
auc1_analysis_heat <- function(societies, n_resamples = 100, seed, dist = 0.2, 
                               formula = "Outcome ~ Income + Education") {
  
  # In: societies: List of societies to analyze;
  #     n_resamples: Number of resamples for stratified bootstrapping (default = 100);
  #     seed: Random seed for reproducibility;
  #     dist: Proportion for splitting data into train and test sets (default = 0.2);
  #     formula: Model formula (default = "Outcome ~ Income + Education").
  # Out: A list containing:
  #       - heatmap: A ggplot2 heatmap visualizing the normalized F-values 
  #                  from the ANOVA test across all societies. The heatmap 
  #                  uses 'b2' (Income~Red coefficient) and 'b3' (Outcome~Income coefficient)
  #                  as axes to compare their impact on bias.
  #       - normalized_df: A data frame summarizing results for each society:
  #           * Society: Name of the society analyzed.
  #           * Fvalue: Raw F-value from the ANOVA test for group differences (Blue vs Red AUC).
  #           * Fvalue_Nrm: Normalized F-value to allow relative comparisons across societies.
  #           * b2: The 'Income~Red' coefficient extracted from the society name.
  #           * b3: The 'Outcome~Income' coefficient extracted from the society name.
  #      - visualisations: A list of visualisations for each society, where each entry contains:
  #           * Vis: The density plot of AUC distributions (from auc_anova_1) 
  #                  for the Blue and Red groups in that society.  
  
  # Load necessary packages
  library(reshape2)
  library(ggplot2)
  
  # Placeholder list to store results and visualisations
  results_list <- list()
  visualisations_list <- list()
  
  # Loop through each society in the provided list of societies
  for (society_name in names(societies)) {
    
    cat("Processing", society_name, "...\n")
    
    # Extract the data for the current society
    data <- societies[[society_name]]
    
    # Run auc1 analysis
    results <- auc_anova_1(data = data$data, 
                           n_resamples = n_resamples,
                           seed = seed, dist = dist, 
                           formula = formula)
    
    # Store the F-value result from the ANOVA summary for the current society
    results_list[[society_name]] <- data.frame(
      Society = society_name,
      Fvalue = results$anova_result[[1]][["F value"]][1])
    
    # Store visualisations for each society
    visualisations_list[[society_name]] <- list(
      Vis = results$visualisation)
  }
  
  # Combine results into a single data frame
  results_df <- do.call(rbind, results_list)
  rownames(results_df) <- NULL  # Reset row names
  results_df <- results_df[, c("Society", "Fvalue")]  # Ensure only necessary columns remain
  
  # Normalize F-values to compare their relative magnitude across societies
  results_df$Fvalue_Nrm <- with(results_df, (Fvalue - min(Fvalue)) / 
                                  (max(Fvalue) - min(Fvalue)))

  # Extract parameters `b2` and `b3` from the society names for heatmap visualisation
  results_df$b2 <- ifelse(
    results_df$Society == "baseline", 
    0.0, 
    as.numeric(sub("b2_([0-9.]+)_.*", "\\1", results_df$Society))
  )

  results_df$b3 <- ifelse(
    results_df$Society == "baseline", 
    0.0, 
    as.numeric(sub(".*_b3_([0-9.]+)", "\\1", results_df$Society))
  )

  # Melt the normalized results_df for heatmap preparation
  heatmap_data <- melt(results_df, id.vars = c("Society", "b2", "b3"), 
                       measure.vars = c("Fvalue_Nrm"),
                       variable.name = "Error_Type", value.name = "Normalized_Fvalue")

  # Plot heatmap with normalized F-values
  heatmap <- ggplot(heatmap_data, aes(x = b2, y = b3, fill = Normalized_Fvalue)) +
    geom_tile() +
    scale_fill_gradient(low = "blue", high = "red", name = "Normalized F-value") +
    labs(title = "Heatmap of Normalized F-Values", 
         x = "Income ~ Red (b2)", 
         y = "Outcome ~ Income (b3)") +
    theme_minimal()

  # Return the heatmap, normalized results dataframe, and visualisations
  return(list(
    heatmap = heatmap,                     # Heatmap for normalized F-values
    normalized_df = results_df,            # Normalized F-values
    visualisations = visualisations_list   # Visualisations for each society
  ))
}
```

## 1.1 Scarce + Linear

```{r message=FALSE, warning=FALSE}
auc1_sl1 <- auc1_analysis_heat(societies = societies_s_l_1, seed = 3983471)
auc1_sl2 <- auc1_analysis_heat(societies = societies_s_l_2, seed = 3983471)
auc1_sl3 <- auc1_analysis_heat(societies = societies_s_l_3, seed = 3983471)
auc1_sl4 <- auc1_analysis_heat(societies = societies_s_l_4, seed = 3983471)
auc1_sl5 <- auc1_analysis_heat(societies = societies_s_l_5, seed = 3983471)
auc1_sl6 <- auc1_analysis_heat(societies = societies_s_l_6, seed = 3983471)
auc1_sl7 <- auc1_analysis_heat(societies = societies_s_l_7, seed = 3983471)
auc1_sl8 <- auc1_analysis_heat(societies = societies_s_l_8, seed = 3983471)
auc1_sl9 <- auc1_analysis_heat(societies = societies_s_l_9, seed = 3983471)
auc1_sl10 <- auc1_analysis_heat(societies = societies_s_l_10, seed = 3983471)
```

## 1.2 Scarce + Non-linear

```{r}
auc1_sn1 <- auc1_analysis_heat(societies = societies_s_n_1, seed = 3983471)
auc1_sn2 <- auc1_analysis_heat(societies = societies_s_n_2, seed = 3983471)
auc1_sn3 <- auc1_analysis_heat(societies = societies_s_n_3, seed = 3983471)
auc1_sn4 <- auc1_analysis_heat(societies = societies_s_n_4, seed = 3983471)
auc1_sn5 <- auc1_analysis_heat(societies = societies_s_n_5, seed = 3983471)
auc1_sn6 <- auc1_analysis_heat(societies = societies_s_n_6, seed = 3983471)
auc1_sn7 <- auc1_analysis_heat(societies = societies_s_n_7, seed = 3983471)
auc1_sn8 <- auc1_analysis_heat(societies = societies_s_n_8, seed = 3983471)
auc1_sn9 <- auc1_analysis_heat(societies = societies_s_n_9, seed = 3983471)
auc1_sn10 <- auc1_analysis_heat(societies = societies_s_n_10, seed = 3983471)
```

## 1.3 Non-scarce + Linear

```{r}
auc1_nl1 <- auc1_analysis_heat(societies = societies_n_l_1, seed = 3983471)
auc1_nl2 <- auc1_analysis_heat(societies = societies_n_l_2, seed = 3983471)
auc1_nl3 <- auc1_analysis_heat(societies = societies_n_l_3, seed = 3983471)
auc1_nl4 <- auc1_analysis_heat(societies = societies_n_l_4, seed = 3983471)
auc1_nl5 <- auc1_analysis_heat(societies = societies_n_l_5, seed = 3983471)
auc1_nl6 <- auc1_analysis_heat(societies = societies_n_l_6, seed = 3983471)
auc1_nl7 <- auc1_analysis_heat(societies = societies_n_l_7, seed = 3983471)
auc1_nl8 <- auc1_analysis_heat(societies = societies_n_l_8, seed = 3983471)
auc1_nl9 <- auc1_analysis_heat(societies = societies_n_l_9, seed = 3983471)
auc1_nl10 <- auc1_analysis_heat(societies = societies_n_l_10, seed = 3983471)
```

## 1.4 Non-scarce + Non-linear

```{r}
auc1_nn1 <- auc1_analysis_heat(societies = societies_n_n_1, seed = 3983471)
auc1_nn2 <- auc1_analysis_heat(societies = societies_n_n_2, seed = 3983471)
auc1_nn3 <- auc1_analysis_heat(societies = societies_n_n_3, seed = 3983471)
auc1_nn4 <- auc1_analysis_heat(societies = societies_n_n_4, seed = 3983471)
auc1_nn5 <- auc1_analysis_heat(societies = societies_n_n_5, seed = 3983471)
auc1_nn6 <- auc1_analysis_heat(societies = societies_n_n_6, seed = 3983471)
auc1_nn7 <- auc1_analysis_heat(societies = societies_n_n_7, seed = 3983471)
auc1_nn8 <- auc1_analysis_heat(societies = societies_n_n_8, seed = 3983471)
auc1_nn9 <- auc1_analysis_heat(societies = societies_n_n_9, seed = 3983471)
auc1_nn10 <- auc1_analysis_heat(societies = societies_n_n_10, seed = 3983471)
```

## 1.5 Correlations

```{r}
calculate_correlations <- function(data, b2_col, b3_col, measure_col, 
                                   dataset_name) {
  
  # In: data: Normalized Wasserstein Distance data frame;
  #     b2_col: A string specifying the column name representing the first variable (e.g., "b2");
  #     b3_col: A string specifying the column name representing the second variable (e.g., "b3");
  #     measure_col: A string specifying the target or measurement column (e.g., "Pos_Mean_Nrm");
  #     dataset_name: A string representing the name of your dataset (e.g., "nl1").
  # Out: A tibble consisting of:
  #         - dataset: The provided dataset name.
  #         - cor_b2: Correlation between the average values of b2_col and measure_col.
  #         - cor_b3: Correlation between the average values of b3_col and measure_col.
  #         - cor_b2_b3: Correlation between the product of b2_col and b3_col and measure_col.
  
  # Load necessary package
  library(dplyr)
  
  # Calculate average measure per group for b2_col
  avg_b3 <- data %>%
    group_by(!!sym(b2_col)) %>% # Group by b2 coefficient
    summarize(avg_measure_b3 = mean(!!sym(measure_col), na.rm = TRUE), .groups = 'drop')

  # Calculate correlation between b2 and measure_col
  cor_b2 <- cor(avg_b3[[b2_col]], avg_b3$avg_measure_b3, use = "complete.obs")

  # Calculate average measure per group for b3_col 
  avg_b2 <- data %>%
    group_by(!!sym(b3_col)) %>% # Group by b3 coefficient
    summarize(avg_measure_b2 = mean(!!sym(measure_col), na.rm = TRUE), .groups = 'drop')

  # Calculate correlation between b3 and measure_col
  cor_b3 <- cor(avg_b2[[b3_col]], avg_b2$avg_measure_b2, use = "complete.obs")

  # Compute product of b2 and b3, then calculate its correlation with measure_col
  data <- data %>%
    mutate(b2_b3 = !!sym(b2_col) * !!sym(b3_col))

  cor_b2_b3 <- cor(data$b2_b3, data[[measure_col]], use = "complete.obs")

  # Return results as a data frame
  correlation_results <- data.frame(
    dataset = dataset_name,   # Dataset name for reference
    cor_b2 = cor_b2,          # Correlation between b2 and measure_col
    cor_b3 = cor_b3,          # Correlation between b3 and measure_col
    cor_b2_b3 = cor_b2_b3,    # Correlation between b2*b3 and measure_col
    stringsAsFactors = FALSE  # To ensure character columns don't become factors
  )
}
```

```{r}
# Load required package
library(purrr)

# List of datasets with names
datasets <- list(
  sl1 = auc1_sl1$normalized_df,
  sl2 = auc1_sl2$normalized_df,
  sl3 = auc1_sl3$normalized_df,
  sl4 = auc1_sl4$normalized_df,
  sl5 = auc1_sl5$normalized_df,
  sl6 = auc1_sl6$normalized_df,
  sl7 = auc1_sl7$normalized_df,
  sl8 = auc1_sl8$normalized_df,
  sl9 = auc1_sl9$normalized_df,
  sl10 = auc1_sl10$normalized_df,
  sn1 = auc1_sn1$normalized_df,
  sn2 = auc1_sn2$normalized_df,
  sn3 = auc1_sn3$normalized_df,
  sn4 = auc1_sn4$normalized_df,
  sn5 = auc1_sn5$normalized_df,
  sn6 = auc1_sn6$normalized_df,
  sn7 = auc1_sn7$normalized_df,
  sn8 = auc1_sn8$normalized_df,
  sn9 = auc1_sn9$normalized_df,
  sn10 = auc1_sn10$normalized_df,
  nl1 = auc1_nl1$normalized_df,
  nl2 = auc1_nl2$normalized_df,
  nl3 = auc1_nl3$normalized_df,
  nl4 = auc1_nl4$normalized_df,
  nl5 = auc1_nl5$normalized_df,
  nl6 = auc1_nl6$normalized_df,
  nl7 = auc1_nl7$normalized_df,
  nl8 = auc1_nl8$normalized_df,
  nl9 = auc1_nl9$normalized_df,
  nl10 = auc1_nl10$normalized_df,
  nn1 = auc1_nn1$normalized_df,
  nn2 = auc1_nn2$normalized_df,
  nn3 = auc1_nn3$normalized_df,
  nn4 = auc1_nn4$normalized_df,
  nn5 = auc1_nn5$normalized_df,
  nn6 = auc1_nn6$normalized_df,
  nn7 = auc1_nn7$normalized_df,
  nn8 = auc1_nn8$normalized_df,
  nn9 = auc1_nn9$normalized_df,
  nn10 = auc1_nn10$normalized_df
)

# Function to calculate correlations across datasets
calculate_results <- function(datasets, measure_col) {
  map2(datasets, names(datasets), ~ calculate_correlations(.x, "b2", "b3", measure_col, .y)) %>%
    bind_rows()
}

# Calculate positive correlations
results_auc1 <- calculate_results(datasets, "Fvalue_Nrm")
print(results_auc1)
```

```{r}
# Calculate average correlations
calculate_avg_correlations <- function(results_df) {
  
  # In: results_df:A dataframe containing the following columns:
  #         - dataset: A string representing the dataset name.
  #         - cor_b2: Correlation between b2 and measure_col.
  #         - cor_b3: Correlation between b3 and measure_col.
  #         - cor_b2_b3: Correlation between the product of b2 and b3 and measure_col.
  # Out: dataset: An abbreviated dataset name (the first two characters of the dataset).
  #      avg_cor_b2: The Fisher-Z inverse transformed average correlation between b2 and measure_col.
  #      avg_cor_b3: The Fisher-Z inverse transformed average correlation between b3 and measure_col.
  #      avg_cor_b2_b3: The Fisher-Z inverse transformed average correlation between the product of b2 and b3 and measure_col.
  
  # Load necessary packages
  library(DescTools)
  library(dplyr)
  
  # Transform dataset names to abbreviated form (first 2 characters)
  results_df %>%
    # Apply Fisher-Z transformation to correlations
    mutate(
      fisher_z_b2_to_avg_b3 = FisherZ(cor_b2),
      fisher_z_b3_to_avg_b2 = FisherZ(cor_b3),
      fisher_z_b2_b3_to_measure = FisherZ(cor_b2_b3)
    ) %>%
    # Group by abbreviated dataset name (first 2 characters)
    group_by(dataset = substr(dataset, 1, 2)) %>%
    summarize(
      avg_fisher_z_b2_to_avg_b3 = mean(fisher_z_b2_to_avg_b3, na.rm = TRUE),
      avg_fisher_z_b3_to_avg_b2 = mean(fisher_z_b3_to_avg_b2, na.rm = TRUE),
      avg_fisher_z_b2_b3_to_measure = mean(fisher_z_b2_b3_to_measure, na.rm = TRUE),
      .groups = 'drop'
    ) %>%
    # Apply Fisher-Z inverse transformation back to correlation scale
    mutate(
      avg_cor_b2 = FisherZInv(avg_fisher_z_b2_to_avg_b3),
      avg_cor_b3 = FisherZInv(avg_fisher_z_b3_to_avg_b2),
      avg_cor_b2_b3 = FisherZInv(avg_fisher_z_b2_b3_to_measure)
    ) %>%
    # Select relevant columns
    select(dataset, avg_cor_b2, avg_cor_b3, avg_cor_b2_b3)
}
```

```{r}
# Calculate average correlations for auc1
avg_results_auc1 <- calculate_avg_correlations(results_auc1)
print(avg_results_auc1)
```

# 2. Scenario 2A

**Scenario 2A**: A model is trained only on the “Blue” group and tested separately on both “Blue” and “Red” groups, with AUC calculated for each.

```{r}
# Function for Scenario 2: Train on Blue and Test on Blue/Red
auc_anova_2 <- function(data, variable1 = "Colour", variable2 = "Disability", 
                        n_resamples = 100, seed, dist = 0.2, 
                        formula = "Outcome ~ Income + Education", 
                        family = binomial, response = "Outcome") {
  
  # In: data: The dataset used for bootstrapping and modeling;
  #      variable1: A string indicating the first categorical variable (default = "Colour");
  #      variable2: A string indicating the second categorical variable (default = "Disability");
  #      n_resamples: Number of resamples for stratified bootstrapping (default = 100);
  #      seed: Seed for reproducibility;
  #      dist: Proportion for splitting data into train and test sets (default = 0.2);
  #      formula: A formula specifying the model (default = Outcome ~ Income + Education);
  #      family: The family for the GLM model (default = binomial);
  #      response: The name of the response variable as a string (response = "Outcome").
  # Out: A list containing the following elements:
  #      - mean_auc: A data frame summarizing the mean AUC values for each train-test scenario.
  #                 * train_color: The group on which the model was trained (e.g., "Blue").
  #                 * test_color: The group on which the model was tested (e.g., "Blue" or "Red").
  #                 * mean_auc: The average AUC across all bootstrap iterations for the given scenario.
  #      - AUC_result: A data frame in long format containing the AUC values 
  #                    for each bootstrap iteration and each group (Blue and Red).
  #                    Columns include:
  #                  * Bootstrap: The bootstrap iteration number.
  #                  * Group: The group (Blue or Red) for which AUC is calculated.
  #                  * AUC: The AUC value for that group in the given iteration.
  #      - anova_result: The summary of an ANOVA test performed on the AUC values
  #                      to assess whether there are significant differences 
  #                      between the Blue and Red groups.
  #      - visualisation: A ggplot2 density plot visualizing the distribution of AUC values 
  #                       for each train-test scenario ("Blue on Blue" and "Blue on Red"). 
  
  # Load required packages
  library(dplyr)
  library(pROC)
  library(ggplot2)
  
  # Generate n_bootstrap samples using the bootstrap function
  bootstrap_samples <- stratified_bootstrap(data = data, 
                                            variable1 = variable1, 
                                            variable2 = variable2, 
                                            n_resamples = n_resamples,
                                            seed = seed)
  
  # Initialize a data frame to store AUC results in long format
  auc_results <- data.frame(Bootstrap = integer(), train_color = character(), 
                            test_color = character(), AUC = numeric())

  # Loop through each bootstrap sample
  for (i in 1:n_resamples) {
    
    # Get the current bootstrap sample
    sample <- bootstrap_samples[[i]]
    
    # Split the bootstrap sample into train and test sets
    set.seed(seed)
    test.index <- sample(nrow(sample), nrow(sample) * dist) 
    train <- sample[-test.index, ]
    test <- sample[test.index, ]

    # Train on the "Blue" group (Colour = 0)
    blue_train <- train %>% filter(!!sym(variable1) == 0)  # Filter rows where Colour = 0 (Blue)
    if (nrow(blue_train) > 0) {
      
      # Train a GLM model on the Blue training set
      blue_model <- glm(formula = formula, data = blue_train, family = family)

      # Test on Blue group
      test_blue <- test %>% filter(!!sym(variable1) == 0)
      if (nrow(test_blue) > 0) {
        # Predict probabilities and calculate AUC
        test_blue$predicted_prob <- predict(blue_model, newdata = test_blue, type = "response")
        auc_blue_test <- roc(test_blue[[response]], test_blue$predicted_prob)$auc
        
        # Store the result
        auc_results <- rbind(auc_results, data.frame(bootstrap = i, 
                                                      train_color = "Blue", 
                                                      test_color = "Blue", 
                                                      AUC = auc_blue_test))
      }

      # Test on Red group
      test_red <- test %>% filter(!!sym(variable1) == 1)  # Filter rows where Colour = 1 (Red)
      if (nrow(test_red) > 0) {
        # Predict probabilities and calculate AUC
        test_red$predicted_prob <- predict(blue_model, newdata = test_red, type = "response")
        auc_red_test <- roc(test_red[[response]], test_red$predicted_prob)$auc
        
        # Store the result
        auc_results <- rbind(auc_results, data.frame(bootstrap = i, 
                                                      train_color = "Blue", 
                                                      test_color = "Red", 
                                                      AUC = auc_red_test))
      }
    }
  }

  # Calculate mean AUCs for each train-test scenario
  mean_auc <- auc_results %>%
    group_by(train_color, test_color) %>%
    summarize(mean_auc = mean(AUC), .groups = 'drop')

  # Perform ANOVA to compare AUC values across scenarios
  # Add a 'scenario' column to categorize AUC results
  auc_results <- auc_results %>%
    mutate(scenario = paste(train_color, "on", test_color))

  # Perform one-way ANOVA on the AUC values by scenario
  anova_result <- aov(AUC ~ scenario, data = auc_results)

  # Visualisation - Density plot of AUC distributions
  plot <- ggplot(auc_results, aes(x = AUC, fill = scenario)) +
    geom_density(alpha = 0.5) +
    scale_fill_brewer(palette = "Set1") +
    labs(title = "Density Plot of AUC Distributions by Scenario",
         x = "AUC",
         y = "Density",
         fill = "Scenario") +
    theme_minimal()
  
  # Return all results
  return(list(mean_auc = mean_auc,                   # Mean AUC values
              AUC_results = auc_results,             # All bootstrap AUC results
              anova_result = summary(anova_result),  # ANOVA results summary
              visualisation = plot))                 # Density plot visualisation
}
```

```{r}
auc2_analysis_heat <- function(societies, n_resamples = 100, seed, dist = 0.2, 
                               formula = "Outcome ~ Income + Education") {
  
  # In: societies: List of societies to analyze;
  #     n_resamples: Number of resamples for stratified bootstrapping (default = 100);
  #     seed: Random seed for reproducibility;
  #     dist: Proportion for splitting data into train and test sets (default = 0.2);
  #     formula: Model formula (default = "Outcome ~ Income + Education").
  # Out: A list containing:
  #       - heatmap: A ggplot2 heatmap visualizing the normalized F-values 
  #                  from the ANOVA test across all societies. The heatmap 
  #                  uses 'b2' (Income~Red coefficient) and 'b3' (Outcome~Income coefficient)
  #                  as axes to compare their impact on bias.
  #       - normalized_df: A data frame summarizing results for each society:
  #           * Society: Name of the society analyzed.
  #           * Fvalue: Raw F-value from the ANOVA test for group differences (Blue vs Red AUC).
  #           * Fvalue_Nrm: Normalized F-value to allow relative comparisons across societies.
  #           * b2: The 'Income~Red' coefficient extracted from the society name.
  #           * b3: The 'Outcome~Income' coefficient extracted from the society name.
  #      - visualisations: A list of visualisations for each society, where each entry contains:
  #           * Vis: The density plot of AUC distributions (from auc_anova_1) 
  #                  for the Blue and Red groups in that society.  
  
  # Load required packages
  library(reshape2)
  library(ggplot2)
  
  # Placeholder list to store results and visualisations
  results_list <- list()
  visualisations_list <- list()
  
  # Run analysis for each society in the list
  for (society_name in names(societies)) {
    
    cat("Processing", society_name, "...\n")
    
    # Extract society data
    data <- societies[[society_name]]
    
    # Run error variance analysis
    results <- auc_anova_2(data = data$data, 
                           n_resamples = n_resamples,
                           seed = seed, dist = dist, 
                           formula = formula)
    
    # Store results with society name
    results_list[[society_name]] <- data.frame(
      Society = society_name,
      Fvalue = results$anova_result[[1]][["F value"]][1])
    
    # Store visualisations for each society
    visualisations_list[[society_name]] <- list(
      Vis = results$visualisation)
  }
  
  # Combine results into a single data frame
  results_df <- do.call(rbind, results_list)
  rownames(results_df) <- NULL  # Reset row names
  results_df <- results_df[, c("Society", "Fvalue")]  # Ensure only necessary columns remain
  
  # Normalize F-values in results_df
  results_df$Fvalue_Nrm <- with(results_df, (Fvalue - min(Fvalue)) / 
                                  (max(Fvalue) - min(Fvalue)))

  # Extract `b2` and `b3` from society names for visualisation
  results_df$b2 <- ifelse(
    results_df$Society == "baseline", 
    0.0, 
    as.numeric(sub("b2_([0-9.]+)_.*", "\\1", results_df$Society))
  )

  results_df$b3 <- ifelse(
    results_df$Society == "baseline", 
    0.0, 
    as.numeric(sub(".*_b3_([0-9.]+)", "\\1", results_df$Society))
  )

  # Melt the normalized results_df for heatmap preparation
  heatmap_data <- melt(results_df, id.vars = c("Society", "b2", "b3"), 
                       measure.vars = c("Fvalue_Nrm"),
                       variable.name = "Error_Type", value.name = "Normalized_Fvalue")

  # Plot heatmap with normalized F-values
  heatmap <- ggplot(heatmap_data, aes(x = b2, y = b3, fill = Normalized_Fvalue)) +
    geom_tile() +
    scale_fill_gradient(low = "blue", high = "red", name = "Normalized F-value") +
    labs(title = "Heatmap of Normalized F-values", 
         x = "Income ~ Red (b2)", 
         y = "Outcome ~ Income (b3)") +
    theme_minimal()

  # Return the heatmap, normalized results dataframe, and visualisations
  return(list(
    heatmap = heatmap,                     # Heatmap for normalized F-values
    normalized_df = results_df,            # Normalized F-values
    visualisations = visualisations_list   # Visualisations for each society
  ))
}
```

## 2.1 Scarce + Linear

```{r message=FALSE, warning=FALSE}
auc2_sl1 <- auc2_analysis_heat(societies = societies_s_l_1, seed = 3983471)
auc2_sl2 <- auc2_analysis_heat(societies = societies_s_l_2, seed = 3983471)
auc2_sl3 <- auc2_analysis_heat(societies = societies_s_l_3, seed = 3983471)
auc2_sl4 <- auc2_analysis_heat(societies = societies_s_l_4, seed = 3983471)
auc2_sl5 <- auc2_analysis_heat(societies = societies_s_l_5, seed = 3983471)
auc2_sl6 <- auc2_analysis_heat(societies = societies_s_l_6, seed = 3983471)
auc2_sl7 <- auc2_analysis_heat(societies = societies_s_l_7, seed = 3983471)
auc2_sl8 <- auc2_analysis_heat(societies = societies_s_l_8, seed = 3983471)
auc2_sl9 <- auc2_analysis_heat(societies = societies_s_l_9, seed = 3983471)
auc2_sl10 <- auc2_analysis_heat(societies = societies_s_l_10, seed = 3983471)
```

## 2.2 Scarce + Non-linear

```{r}
auc2_sn1 <- auc2_analysis_heat(societies = societies_s_n_1, seed = 3983471)
auc2_sn2 <- auc2_analysis_heat(societies = societies_s_n_2, seed = 3983471)
auc2_sn3 <- auc2_analysis_heat(societies = societies_s_n_3, seed = 3983471)
auc2_sn4 <- auc2_analysis_heat(societies = societies_s_n_4, seed = 3983471)
auc2_sn5 <- auc2_analysis_heat(societies = societies_s_n_5, seed = 3983471)
auc2_sn6 <- auc2_analysis_heat(societies = societies_s_n_6, seed = 3983471)
auc2_sn7 <- auc2_analysis_heat(societies = societies_s_n_7, seed = 3983471)
auc2_sn8 <- auc2_analysis_heat(societies = societies_s_n_8, seed = 3983471)
auc2_sn9 <- auc2_analysis_heat(societies = societies_s_n_9, seed = 3983471)
auc2_sn10 <- auc2_analysis_heat(societies = societies_s_n_10, seed = 3983471)
```

## 2.3 Non-scarce + Linear

```{r}
auc2_nl1 <- auc2_analysis_heat(societies = societies_n_l_1, seed = 3983471)
auc2_nl2 <- auc2_analysis_heat(societies = societies_n_l_2, seed = 3983471)
auc2_nl3 <- auc2_analysis_heat(societies = societies_n_l_3, seed = 3983471)
auc2_nl4 <- auc2_analysis_heat(societies = societies_n_l_4, seed = 3983471)
auc2_nl5 <- auc2_analysis_heat(societies = societies_n_l_5, seed = 3983471)
auc2_nl6 <- auc2_analysis_heat(societies = societies_n_l_6, seed = 3983471)
auc2_nl7 <- auc2_analysis_heat(societies = societies_n_l_7, seed = 3983471)
auc2_nl8 <- auc2_analysis_heat(societies = societies_n_l_8, seed = 3983471)
auc2_nl9 <- auc2_analysis_heat(societies = societies_n_l_9, seed = 3983471)
auc2_nl10 <- auc2_analysis_heat(societies = societies_n_l_10, seed = 3983471)
```

## 2.4 Non-scarce + Non-linear

```{r}
auc2_nn1 <- auc2_analysis_heat(societies = societies_n_n_1, seed = 3983471)
auc2_nn2 <- auc2_analysis_heat(societies = societies_n_n_2, seed = 3983471)
auc2_nn3 <- auc2_analysis_heat(societies = societies_n_n_3, seed = 3983471)
auc2_nn4 <- auc2_analysis_heat(societies = societies_n_n_4, seed = 3983471)
auc2_nn5 <- auc2_analysis_heat(societies = societies_n_n_5, seed = 3983471)
auc2_nn6 <- auc2_analysis_heat(societies = societies_n_n_6, seed = 3983471)
auc2_nn7 <- auc2_analysis_heat(societies = societies_n_n_7, seed = 3983471)
auc2_nn8 <- auc2_analysis_heat(societies = societies_n_n_8, seed = 3983471)
auc2_nn9 <- auc2_analysis_heat(societies = societies_n_n_9, seed = 3983471)
auc2_nn10 <- auc2_analysis_heat(societies = societies_n_n_10, seed = 3983471)
```

## 2.5 Correlations

```{r}
# List of datasets with names
datasets <- list(
  sl1 = auc2_sl1$normalized_df,
  sl2 = auc2_sl2$normalized_df,
  sl3 = auc2_sl3$normalized_df,
  sl4 = auc2_sl4$normalized_df,
  sl5 = auc2_sl5$normalized_df,
  sn1 = auc2_sn1$normalized_df,
  sn2 = auc2_sn2$normalized_df,
  sn3 = auc2_sn3$normalized_df,
  sn4 = auc2_sn4$normalized_df,
  sn5 = auc2_sn5$normalized_df,
  nl1 = auc2_nl1$normalized_df,
  nl2 = auc2_nl2$normalized_df,
  nl3 = auc2_nl3$normalized_df,
  nl4 = auc2_nl4$normalized_df,
  nl5 = auc2_nl5$normalized_df,
  nn1 = auc2_nn1$normalized_df,
  nn2 = auc2_nn2$normalized_df,
  nn3 = auc2_nn3$normalized_df,
  nn4 = auc2_nn4$normalized_df,
  nn5 = auc2_nn5$normalized_df
)

# Function to calculate correlations across datasets
calculate_results <- function(datasets, measure_col) {
  map2(datasets, names(datasets), ~ calculate_correlations(.x, "b2", "b3", measure_col, .y)) %>%
    bind_rows()
}

# Calculate auc1 correlations
results_auc2 <- calculate_results(datasets, "Fvalue_Nrm")
print(results_auc2)
```

```{r}
# Calculate average correlations for auc1
avg_results_auc2 <- calculate_avg_correlations(results_auc2)

# Print results
print(avg_results_auc2)
```

# 3. Scenario 2B

**Scenario 2B**: A model is trained only on the “Red” group and tested separately on both “Blue” and “Red” groups, again calculating AUC for each.

```{r}
# Function for Scenario 3: Train on Red and Test on Blue/Red
auc_anova_3 <- function(data, variable1 = "Colour", variable2 = "Disability", 
                        n_resamples = 100, seed, dist = 0.2, 
                        formula = "Outcome ~ Income + Education", family = binomial, 
                        response = "Outcome") {
  
  # In: data: The dataset used for bootstrapping and modeling;
  #      variable1: A string indicating the first categorical variable (default = "Colour");
  #      variable2: A string indicating the second categorical variable (default = "Disability");
  #      n_resamples: Number of resamples for stratified bootstrapping (default = 100);
  #      seed: Seed for reproducibility;
  #      dist: Proportion for splitting data into train and test sets (default = 0.2);
  #      formula: A formula specifying the model (e.g., Outcome ~ Income + Education);
  #      family: The family for the GLM model (default = binomial);
  #      response: The name of the response variable as a string (default = "Outcome").
  # Out: ANOVA results and mean AUC values across the bootstrap samples.
  
  # Load relevant packages
  library(dplyr)
  library(pROC)
  library(ggplot2)
  
  # Generate n_bootstrap samples using the bootstrap function
  bootstrap_samples <- stratified_bootstrap(data = data, 
                                            variable1 = variable1, 
                                            variable2 = variable2, 
                                            n_resamples = n_resamples,
                                            seed = seed)
  
  # Initialize a data frame to store AUC results in long format
  auc_results <- data.frame(Bootstrap = integer(), train_color = character(), 
                            test_color = character(), AUC = numeric())

  # Loop through each bootstrap sample
  for (i in 1:n_resamples) {
    
    # Get the current bootstrap sample
    sample <- bootstrap_samples[[i]]
    
    # Split the bootstrap sample into train and test sets
    set.seed(seed)
    test.index <- sample(nrow(sample), nrow(sample) * dist) 
    train <- sample[-test.index, ]
    test <- sample[test.index, ]

    red_train <- train %>% filter(!!sym(variable1) == 1)  # 1 = "Red"
    if (nrow(red_train) > 0) {
      red_model <- glm(formula = formula, data = red_train, family = family)

      test_blue <- test %>% filter(!!sym(variable1) == 0)  # 0 = "Blue"
      if (nrow(test_blue) > 0) {
        test_blue$predicted_prob <- predict(red_model, newdata = test_blue, type = "response")
        auc_blue_test <- roc(test_blue[[response]], test_blue$predicted_prob)$auc
        auc_results <- rbind(auc_results, data.frame(Bootstrap = i, 
                                                      train_color = "Red", 
                                                      test_color = "Blue", 
                                                      AUC = auc_blue_test))
      }

      test_red <- test %>% filter(!!sym(variable1) == 1)
      if (nrow(test_red) > 0) {
        test_red$predicted_prob <- predict(red_model, newdata = test_red, type = "response")
        auc_red_test <- roc(test_red[[response]], test_red$predicted_prob)$auc
        auc_results <- rbind(auc_results, data.frame(Bootstrap = i, 
                                                      train_color = "Red", 
                                                      test_color = "Red", 
                                                      AUC = auc_red_test))
      }
    }
  }

  # Calculate mean AUCs
  mean_auc <- auc_results %>%
    group_by(train_color, test_color) %>%
    summarize(mean_auc = mean(AUC), .groups = 'drop')
  
  # Add a 'scenario' column to categorize each AUC calculation based on training and testing color
  auc_results <- auc_results %>%
    mutate(scenario = paste(train_color, "on", test_color))

  # Perform one-way ANOVA on the AUC values by scenario
  anova_result <- aov(AUC ~ scenario, data = auc_results)
  
  # Visualisation: Density plot of AUC distributions by scenario
  plot <- ggplot(auc_results, aes(x = AUC, fill = scenario)) +
    geom_density(alpha = 0.5) +
    scale_fill_brewer(palette = "Set1") +
    labs(title = "Density Plot of AUC Distributions by Scenario",
         x = "AUC",
         y = "Density",
         fill = "Scenario") +
    theme_minimal()

   return(list(mean_auc = mean_auc, 
               auc_results = auc_results, 
               anova_result = summary(anova_result), 
               visualisation = plot))
}
```

```{r}
auc3_analysis_heat <- function(societies, n_resamples = 100, seed, dist = 0.2, 
                               formula = "Outcome ~ Income + Education") {
  
  # In: societies: List of societies to analyze;
  #     n_resamples: Number of resamples for stratified bootstrapping (default = 100);
  #     seed: Random seed for reproducibility;
  #     dist: Proportion for splitting data into train and test sets (default = 0.2);
  #     formula: Model formula (default = "Outcome ~ Income + Education").
  # Out: auc_results: Data frame with the F-value results of the ANOCA analysis 
  #                   of Blue and Red AUC
  #      heatmap: Heatmap visualisation;
  #      visualisations: List containing visualisations of each samples variances.
  
  # Load relevant packages
  library(reshape2)
  library(ggplot2)
  
  # Placeholder list to store results and visualisations
  results_list <- list()
  visualisations_list <- list()
  
  # Run analysis for each society in the list
  for (society_name in names(societies)) {
    
    cat("Processing", society_name, "...\n")
    
    # Extract society data
    data <- societies[[society_name]]
    
    # Run error variance analysis
    results <- auc_anova_3(data = data$data, 
                           n_resamples = n_resamples,
                           seed = seed, dist = dist, 
                           formula = formula)
    
    # Store results with society name
    results_list[[society_name]] <- data.frame(
      Society = society_name,
      Fvalue = results$anova_result[[1]][["F value"]][1])
    
    # Store visualisations for each society
    visualisations_list[[society_name]] <- list(
      Vis = results$visualisation)
  }
  
  # Combine results into a single data frame
  results_df <- do.call(rbind, results_list)
  rownames(results_df) <- NULL  # Reset row names
  results_df <- results_df[, c("Society", "Fvalue")]  # Ensure only necessary columns remain
  
  # Normalize F-values in results_df
  results_df$Fvalue_Nrm <- with(results_df, (Fvalue - min(Fvalue)) / (max(Fvalue) - min(Fvalue)))

  # Extract `b2` and `b3` from society names for visualisation
  results_df$b2 <- ifelse(
    results_df$Society == "baseline", 
    0.0, 
    as.numeric(sub("b2_([0-9.]+)_.*", "\\1", results_df$Society))
  )

  results_df$b3 <- ifelse(
    results_df$Society == "baseline", 
    0.0, 
    as.numeric(sub(".*_b3_([0-9.]+)", "\\1", results_df$Society))
  )

  # Melt the normalized results_df for heatmap preparation
  heatmap_data <- melt(results_df, id.vars = c("Society", "b2", "b3"), 
                       measure.vars = c("Fvalue_Nrm"),
                       variable.name = "Error_Type", value.name = "Normalized_Fvalue")

  # Plot heatmap with normalized F-values
  heatmap <- ggplot(heatmap_data, aes(x = b2, y = b3, fill = Normalized_Fvalue)) +
    geom_tile() +
    scale_fill_gradient(low = "blue", high = "red", name = "Normalized F-value") +
    labs(title = "Heatmap of Normalized F-values", 
         x = "Income ~ Red (b2)", 
         y = "Outcome ~ Income (b3)") +
    theme_minimal()

  # Return the heatmap, normalized results dataframe, and visualisations
  return(list(
    heatmap = heatmap,
    normalized_df = results_df,
    visualisations = visualisations_list
  ))
}
```

## 3.1 Scarce + Linear

```{r message=FALSE, warning=FALSE}
auc3_sl1 <- auc3_analysis_heat(societies = societies_s_l_1, seed = 3983471)
auc3_sl2 <- auc3_analysis_heat(societies = societies_s_l_2, seed = 3983471)
auc3_sl3 <- auc3_analysis_heat(societies = societies_s_l_3, seed = 3983471)
auc3_sl4 <- auc3_analysis_heat(societies = societies_s_l_4, seed = 3983471)
auc3_sl5 <- auc3_analysis_heat(societies = societies_s_l_5, seed = 3983471)
auc3_sl6 <- auc3_analysis_heat(societies = societies_s_l_6, seed = 3983471)
auc3_sl7 <- auc3_analysis_heat(societies = societies_s_l_7, seed = 3983471)
auc3_sl8 <- auc3_analysis_heat(societies = societies_s_l_8, seed = 3983471)
auc3_sl9 <- auc3_analysis_heat(societies = societies_s_l_9, seed = 3983471)
auc3_sl10 <- auc3_analysis_heat(societies = societies_s_l_10, seed = 3983471)
```

## 3.2 Scarce + Non-linear

```{r}
auc3_sn1 <- auc3_analysis_heat(societies = societies_s_n_1, seed = 3983471)
auc3_sn2 <- auc3_analysis_heat(societies = societies_s_n_2, seed = 3983471)
auc3_sn3 <- auc3_analysis_heat(societies = societies_s_n_3, seed = 3983471)
auc3_sn4 <- auc3_analysis_heat(societies = societies_s_n_4, seed = 3983471)
auc3_sn5 <- auc3_analysis_heat(societies = societies_s_n_5, seed = 3983471)
auc3_sn6 <- auc3_analysis_heat(societies = societies_s_n_6, seed = 3983471)
auc3_sn7 <- auc3_analysis_heat(societies = societies_s_n_7, seed = 3983471)
auc3_sn8 <- auc3_analysis_heat(societies = societies_s_n_8, seed = 3983471)
auc3_sn9 <- auc3_analysis_heat(societies = societies_s_n_9, seed = 3983471)
auc3_sn10 <- auc3_analysis_heat(societies = societies_s_n_10, seed = 3983471)
```

## 3.3 Non-scarce + Linear

```{r}
auc3_nl1 <- auc3_analysis_heat(societies = societies_n_l_1, seed = 3983471)
auc3_nl2 <- auc3_analysis_heat(societies = societies_n_l_2, seed = 3983471)
auc3_nl3 <- auc3_analysis_heat(societies = societies_n_l_3, seed = 3983471)
auc3_nl4 <- auc3_analysis_heat(societies = societies_n_l_4, seed = 3983471)
auc3_nl5 <- auc3_analysis_heat(societies = societies_n_l_5, seed = 3983471)
auc3_nl6 <- auc3_analysis_heat(societies = societies_n_l_6, seed = 3983471)
auc3_nl7 <- auc3_analysis_heat(societies = societies_n_l_7, seed = 3983471)
auc3_nl8 <- auc3_analysis_heat(societies = societies_n_l_8, seed = 3983471)
auc3_nl9 <- auc3_analysis_heat(societies = societies_n_l_9, seed = 3983471)
auc3_nl10 <- auc3_analysis_heat(societies = societies_n_l_10, seed = 3983471)
```

## 3.4 Non-scarce + Non-linear

```{r}
auc3_nn1 <- auc3_analysis_heat(societies = societies_n_n_1, seed = 3983471)
auc3_nn2 <- auc3_analysis_heat(societies = societies_n_n_2, seed = 3983471)
auc3_nn3 <- auc3_analysis_heat(societies = societies_n_n_3, seed = 3983471)
auc3_nn4 <- auc3_analysis_heat(societies = societies_n_n_4, seed = 3983471)
auc3_nn5 <- auc3_analysis_heat(societies = societies_n_n_5, seed = 3983471)
auc3_nn6 <- auc3_analysis_heat(societies = societies_n_n_6, seed = 3983471)
auc3_nn7 <- auc3_analysis_heat(societies = societies_n_n_7, seed = 3983471)
auc3_nn8 <- auc3_analysis_heat(societies = societies_n_n_8, seed = 3983471)
auc3_nn9 <- auc3_analysis_heat(societies = societies_n_n_9, seed = 3983471)
auc3_nn10 <- auc3_analysis_heat(societies = societies_n_n_10, seed = 3983471)
```

## 3.5 Correlations

```{r}
# List of datasets with names
datasets <- list(
  sl1 = auc3_sl1$normalized_df,
  sl2 = auc3_sl2$normalized_df,
  sl3 = auc3_sl3$normalized_df,
  sl4 = auc3_sl4$normalized_df,
  sl5 = auc3_sl5$normalized_df,
  sl6 = auc3_sl6$normalized_df,
  sl7 = auc3_sl7$normalized_df,
  sl8 = auc3_sl8$normalized_df,
  sl9 = auc3_sl9$normalized_df,
  sl10 = auc3_sl10$normalized_df,
  sn1 = auc3_sn1$normalized_df,
  sn2 = auc3_sn2$normalized_df,
  sn3 = auc3_sn3$normalized_df,
  sn4 = auc3_sn4$normalized_df,
  sn5 = auc3_sn5$normalized_df,
  sn6 = auc3_sn6$normalized_df,
  sn7 = auc3_sn7$normalized_df,
  sn8 = auc3_sn8$normalized_df,
  sn9 = auc3_sn9$normalized_df,
  sn10 = auc3_sn10$normalized_df,
  nl1 = auc3_nl1$normalized_df,
  nl2 = auc3_nl2$normalized_df,
  nl3 = auc3_nl3$normalized_df,
  nl4 = auc3_nl4$normalized_df,
  nl5 = auc3_nl5$normalized_df,
  nl6 = auc3_nl6$normalized_df,
  nl7 = auc3_nl7$normalized_df,
  nl8 = auc3_nl8$normalized_df,
  nl9 = auc3_nl9$normalized_df,
  nl10 = auc3_nl10$normalized_df,
  nn1 = auc3_nn1$normalized_df,
  nn2 = auc3_nn2$normalized_df,
  nn3 = auc3_nn3$normalized_df,
  nn4 = auc3_nn4$normalized_df,
  nn5 = auc3_nn5$normalized_df,
  nn6 = auc3_nn6$normalized_df,
  nn7 = auc3_nn7$normalized_df,
  nn8 = auc3_nn8$normalized_df,
  nn9 = auc3_nn9$normalized_df,
  nn10 = auc3_nn10$normalized_df
)

# Function to calculate correlations across datasets
calculate_results <- function(datasets, measure_col) {
  map2(datasets, names(datasets), ~ calculate_correlations(.x, "b2", "b3", measure_col, .y)) %>%
    bind_rows()
}

# Calculate positive correlations
results_auc3 <- calculate_results(datasets, "Fvalue_Nrm")
print(results_auc3)
```

```{r}
# Calculate average correlations for auc1
avg_results_auc3 <- calculate_avg_correlations(results_auc3)
print(avg_results_auc3)
```